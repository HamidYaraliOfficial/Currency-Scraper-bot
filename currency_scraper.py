import requests
from bs4 import BeautifulSoup
from datetime import datetime
import re
from typing import Dict, List, Union, Optional
import json
from dataclasses import dataclass
from urllib.parse import urljoin

@dataclass
class CurrencyConfig:
    path: str
    flag: str

class CurrencyScraper:
    """A class to scrape currency exchange rates from tejaratnews.com."""
    
    BASE_URL = "https://tejaratnews.com/"
    CURRENCIES = {
        "Ø¯Ù„Ø§Ø±": CurrencyConfig(path="Ù‚ÛŒÙ…Øª-Ø¯Ù„Ø§Ø±", flag="ğŸ‡ºğŸ‡¸"),
        "ÛŒÙˆØ±Ùˆ": CurrencyConfig(path="Ù‚ÛŒÙ…Øª-ÛŒÙˆØ±Ùˆ", flag="ğŸ‡ªğŸ‡º"),
        "Ù¾ÙˆÙ†Ø¯": CurrencyConfig(path="Ù‚ÛŒÙ…Øª-Ù¾ÙˆÙ†Ø¯", flag="ğŸ‡¬ğŸ‡§"),
        "Ø¯Ø±Ù‡Ù… Ø§Ù…Ø§Ø±Ø§Øª": CurrencyConfig(path="Ù‚ÛŒÙ…Øª-Ø¯Ø±Ù‡Ù…-Ø§Ù…Ø§Ø±Ø§Øª", flag="ğŸ‡¦ğŸ‡ª"),
        "Ù„ÛŒØ± ØªØ±Ú©ÛŒÙ‡": CurrencyConfig(path="Ù‚ÛŒÙ…Øª-Ù„ÛŒØ±-ØªØ±Ú©ÛŒÙ‡", flag="ğŸ‡¹ğŸ‡·"),
        "ÛŒÙˆØ§Ù† Ú†ÛŒÙ†": CurrencyConfig(path="Ù‚ÛŒÙ…Øª-ÛŒÙˆØ§Ù†-Ú†ÛŒÙ†", flag="ğŸ‡¨ğŸ‡³"),
        "Ø±ÙˆØ¨Ù„ Ø±ÙˆØ³ÛŒÙ‡": CurrencyConfig(path="Ù‚ÛŒÙ…Øª-Ø±ÙˆØ¨Ù„-Ø±ÙˆØ³ÛŒÙ‡", flag="ğŸ‡·ğŸ‡º"),
        "Ø¯ÛŒÙ†Ø§Ø± Ø¹Ø±Ø§Ù‚": CurrencyConfig(path="Ù‚ÛŒÙ…Øª-Ø¯ÛŒÙ†Ø§Ø±-Ø¹Ø±Ø§Ù‚", flag="ğŸ‡®ğŸ‡¶"),
        "Ø¯Ù„Ø§Ø± Ú©Ø§Ù†Ø§Ø¯Ø§": CurrencyConfig(path="Ù‚ÛŒÙ…Øª-Ø¯Ù„Ø§Ø±-Ú©Ø§Ù†Ø§Ø¯Ø§", flag="ğŸ‡¨ğŸ‡¦"),
        "Ø§ÙØºØ§Ù†ÛŒ Ø§ÙØºØ§Ù†Ø³ØªØ§Ù†": CurrencyConfig(path="Ù‚ÛŒÙ…Øª-Ø§ÙØºØ§Ù†ÛŒ-Ø§ÙØºØ§Ù†Ø³ØªØ§Ù†", flag="ğŸ‡¦ğŸ‡«"),
        "Ø±ÛŒØ§Ù„ Ù‚Ø·Ø±": CurrencyConfig(path="Ù‚ÛŒÙ…Øª-Ø±ÛŒØ§Ù„-Ù‚Ø·Ø±", flag="ğŸ‡¶ğŸ‡¦"),
        "Ø±ÛŒØ§Ù„ Ø¹Ù…Ø§Ù†": CurrencyConfig(path="Ù‚ÛŒÙ…Øª-Ø±ÛŒØ§Ù„-Ø¹Ù…Ø§Ù†", flag="ğŸ‡´ğŸ‡²"),
        "Ø¯Ù„Ø§Ø± Ø§Ø³ØªØ±Ø§Ù„ÛŒØ§": CurrencyConfig(path="Ù‚ÛŒÙ…Øª-Ø¯Ù„Ø§Ø±-Ø§Ø³ØªØ±Ø§Ù„ÛŒØ§", flag="ğŸ‡¦ğŸ‡º"),
        "Ú©Ø±ÙˆÙ† Ø³ÙˆØ¦Ø¯": CurrencyConfig(path="Ù‚ÛŒÙ…Øª-Ú©Ø±ÙˆÙ†-Ø³ÙˆØ¦Ø¯", flag="ğŸ‡¸ğŸ‡ª"),
        "Ø¯Ø±Ø§Ù… Ø§Ø±Ù…Ù†Ø³ØªØ§Ù†": CurrencyConfig(path="Ù‚ÛŒÙ…Øª-Ø¯Ø±Ø§Ù…-Ø§Ø±Ù…Ù†Ø³ØªØ§Ù†", flag="ğŸ‡¦ğŸ‡²"),
        "Ù…Ù†Ø§Øª Ø¢Ø°Ø±Ø¨Ø§ÛŒØ¬Ø§Ù†": CurrencyConfig(path="Ù‚ÛŒÙ…Øª-Ù…Ù†Ø§Øª-Ø§Ø°Ø±Ø¨Ø§ÛŒØ¬Ø§Ù†", flag="ğŸ‡¦ğŸ‡¿"),
        "ÙØ±Ø§Ù†Ú© Ø³ÙˆØ¦ÛŒØ³": CurrencyConfig(path="Ù‚ÛŒÙ…Øª-ÙØ±Ø§Ù†Ú©-Ø³ÙˆØ¦ÛŒØ³", flag="ğŸ‡¨ğŸ‡­"),
        "Ú©Ø±ÙˆÙ† Ø¯Ø§Ù†Ù…Ø§Ø±Ú©": CurrencyConfig(path="Ù‚ÛŒÙ…Øª-Ú©Ø±ÙˆÙ†-Ø¯Ø§Ù†Ù…Ø§Ø±Ú©", flag="ğŸ‡©ğŸ‡°"),
        "Ø±ÙˆÙ¾ÛŒÙ‡ Ù‡Ù†Ø¯": CurrencyConfig(path="Ù‚ÛŒÙ…Øª-Ø±ÙˆÙ¾ÛŒÙ‡-Ù‡Ù†Ø¯", flag="ğŸ‡®ğŸ‡³"),
        "Ø±ÛŒÙ†Ú¯ÛŒØª Ù…Ø§Ù„Ø²ÛŒ": CurrencyConfig(path="Ù‚ÛŒÙ…Øª-Ø±ÛŒÙ†Ú¯ÛŒØª-Ù…Ø§Ù„Ø²ÛŒ", flag="ğŸ‡²ğŸ‡¾"),
        "Ú©Ø±ÙˆÙ† Ù†Ø±ÙˆÚ˜": CurrencyConfig(path="Ù‚ÛŒÙ…Øª-Ú©Ø±ÙˆÙ†-Ù†Ø±ÙˆÚ˜", flag="ğŸ‡³ğŸ‡´"),
        "Ø±ÛŒØ§Ù„ Ø¹Ø±Ø¨Ø³ØªØ§Ù†": CurrencyConfig(path="Ù‚ÛŒÙ…Øª-Ø±ÛŒØ§Ù„-Ø¹Ø±Ø¨Ø³ØªØ§Ù†", flag="ğŸ‡¸ğŸ‡¦"),
        "Ø¯Ù„Ø§Ø± Ø³Ù†Ú¯Ø§Ù¾ÙˆØ±": CurrencyConfig(path="Ù‚ÛŒÙ…Øª-Ø¯Ù„Ø§Ø±-Ø³Ù†Ú¯Ø§Ù¾ÙˆØ±", flag="ğŸ‡¸ğŸ‡¬"),
    }
    
    def __init__(self):
        """Initialize the scraper with a requests session."""
        self.session = requests.Session()
        self.session.headers.update({
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        })

    def fetch_html(self, url: str) -> str:
        """
        Fetch HTML content from the specified URL.
        
        Args:
            url (str): The URL to fetch HTML from.
            
        Returns:
            str: The HTML content.
            
        Raises:
            RuntimeError: If the HTTP request fails or returns invalid content.
        """
        try:
            response = self.session.get(
                url,
                timeout=30,
                allow_redirects=True,
                verify=False  # Equivalent to CURLOPT_SSL_VERIFYPEER = false
            )
            response.raise_for_status()
            return response.text
        except requests.RequestException as e:
            raise RuntimeError(f"Failed to fetch HTML from {url}: {str(e)}")

    def parse_price(self, html: str, currency_name: str) -> Dict[str, Union[str, List, Optional[str]]]:
        """
        Parse price data from HTML content for a specific currency.
        
        Args:
            html (str): The HTML content to parse.
            currency_name (str): The name of the currency to extract data for.
            
        Returns:
            Dict[str, Union[str, List, Optional[str]]]: Parsed data including unit, date, and currency details.
        """
        soup = BeautifulSoup(html, "html.parser")
        data = []
        unit = "ØªÙˆÙ…Ø§Ù†"
        date = None

        # Extract date from tfoot
        tfoot_tds = soup.select("tfoot tr td")
        if tfoot_tds:
            date_match = re.search(r"ØªØ§Ø±ÛŒØ® Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ:\s*([\d\/]+)", tfoot_tds[0].get_text(strip=True))
            if date_match:
                date = date_match.group(1)

        # Parse table rows
        for row in soup.select("table tbody tr"):
            cols = row.find_all("td")
            if len(cols) < 4:
                continue
                
            name = cols[0].get_text(strip=True)
            if name != currency_name:
                continue
                
            try:
                price = int(cols[1].get_text(strip=True).replace(",", ""))
            except ValueError:
                price = 0
                
            data.append({
                "name": name,
                "price": price,
                "change": cols[2].get_text(strip=True),
                "time": cols[3].get_text(strip=True),
            })

        return {"unit": unit, "date": date, "data": data}

    def scrape(self) -> Dict[str, Union[bool, str, Dict]]:
        """
        Scrape currency data for all configured currencies.
        
        Returns:
            Dict[str, Union[bool, str, Dict]]: Scraped data with status and timestamps.
        """
        result = {}
        for name, config in self.CURRENCIES.items():
            try:
                url = urljoin(self.BASE_URL, config.path)
                html = self.fetch_html(url)
                result[name] = {
                    **self.parse_price(html, name),
                    "flag": config.flag
                }
            except RuntimeError as e:
                result[name] = {
                    "error": f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§: {str(e)}",
                    "flag": config.flag
                }

        return {
            "ok": True,
            "updated": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "currencies": result
        }

def main():
    """Main function to run the scraper and output JSON."""
    try:
        scraper = CurrencyScraper()
        result = scraper.scrape()
        print(json.dumps(result, ensure_ascii=False, indent=2))
    except Exception as e:
        print(json.dumps({
            "ok": False,
            "error": "Ø³Ø±ÙˆØ± Ø¨Ø§ Ø®Ø·Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯"
        }, ensure_ascii=False))

if __name__ == "__main__":
    main()